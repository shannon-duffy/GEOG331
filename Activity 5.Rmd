---
title: "Activity 5"
author: "Shannon Duffy"
date: "10/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Question 1: Given the description and location of the stream, what factors would you expect to influence streamflow? Would there be times that you might expect higher flow than would be typical for a given amount of rain in the drainage basin?

I would expect that flow would increase over time as popluation increased because this is in a populated area which indicates the paved area has increased and also with more people there is more flow from the sewer lines that feed into the river. It's also located in an area with great temperature variability and snowfall, so I expect spring months will have higher flow because of snow melt.

```{r}
#read data
library(dplyr)
library(lubridate)
datH<-read.csv('stream_flow_data.csv', na.strings = c("Eqp"))
datP <- read.csv("data5/2049867.csv")
```
```{r}
#select just reliable/publishable data
datD <- datH[datH$discharge.flag == "A",]
```
```{r}
#convert dates
#### define time for streamflow #####
#convert date and time
datesD <- as.Date(datD$date, "%m/%d/%Y")
#get day of year
datD$doy <- yday(datesD)
#calculate year
datD$year <- year(datesD)
#define time
timesD <- hm(datD$time)

#### define time for precipitation #####    
dateP <- ymd_hm(datP$DATE)
#get day of year
datP$doy <- yday(dateP)
#get year 
datP$year <- year(dateP)

#### get decimal formats #####
#convert time from a string to a more usable format
#with a decimal hour
datD$hour <- hour(timesD ) + (minute(timesD )/60)
#get full decimal time
datD$decDay <- datD$doy + (datD$hour/24)
#calculate a decimal year, but account for leap year
datD$decYear <- ifelse(leap_year(datD$year),datD$year + (datD$decDay/366), datD$year + (datD$decDay/365))
#calculate times for datP                       
datP$hour <- hour(dateP ) + (minute(dateP )/60)
#get full decimal time
datP$decDay <- datP$doy + (datP$hour/24)
#calculate a decimal year, but account for leap year
datP$decYear <- ifelse(leap_year(datP$year),datP$year + (datP$decDay/366), datP$year + (datP$decDay/365))      
```

Question 2: Explain how decimal year is calculated and how leap year is accounted for. What do the results of the leap_year function look like?

First, dates must be recongizable as dates which can be achieved with the as.Date function. Decimal hour is calculated by converting minutes to decimal hours by selecting the minutes of the time object created with the hm function and dividing by 60 and adding to the hours of the time object created with hm. Then to convert that new object to decimal days, it is divided by 24 and added to the doy created with the yday function. Then the decimal year is created by taking that new object, dividing it by 365 (or 366 for leap years), and adding it to the year created with the year function. The leap_year function takes a value that is recognized as a year and returns TRUE if that year was a leap year or FALSE if it was not. The ifelse function selects those years deemed as leap years by the leap_year function and divides the decimal day by 366 and adds it to the year. For all other years, the decimal day is divided by 365 and added to the year.


Question 3: How many observations are in the stream flow and precipitation data? What is the frequency of the observations for each data type?
```{r}
length(datD$discharge)
length (datP$HPCP)
```
There are 393,798 discharge observations and 16,150 precipitation observations. Discharge is measured every 15 minutes and precipitation is measured hourly, but there are some missing values, especially in earlier years.


Question 4: Look up the documentation on the expression function and explain what expression(paste()) in the plot argument did. Are there any issues with this default plot formatting and labels? How does resizing the plot affect these issues?

expression() takes an object - generated by paste()- and recognizes the text as either characters or operations. It recognizes that when we type "^" we want it to superscript the following text, not include the "^" character in the label. The labels don't appear to have any particular issues- they seem to behave like normal labels. As far as formatting goes, the lines are a bit compressed so it's hard to see the variability unless the frame is stretched.

```{r}
#aggregating mean and standard deviation by doy
aveF <- aggregate(datD$discharge, by=list(datD$doy), FUN="mean")
colnames(aveF) <- c("doy","dailyAve")
sdF <- aggregate(datD$discharge, by=list(datD$doy), FUN="sd")
colnames(sdF) <- c("doy","dailySD")
```

Question 5: Add a line that shows the observations for 2017 onto the graph of this average. You may have to adjust the axes limits. Change the x axis label so that they show each month instead of doy. Make the 2017 line a different color than current colors in your plot.
```{r}
#make decimal month column
datD$month <- month(datesD)
datD$day<- day(datesD)
datD$decMonth<-ifelse(datD$month == 1|datD$month == 3|datD$month==5|datD$month==7|datD$month==8|datD$month==10|datD$month==12,datD$month + (datD$day/31), ifelse(datD$month == 2, datD$month + (datD$day/28),
                        datD$month + (datD$day/30)))

#aggregate mean and standard deviation by decimal month
aveDm <- aggregate(datD$discharge, by=list(datD$decMonth), FUN="mean")
colnames(aveDm) <- c("decMonth","dailyAve")
sdDm <- aggregate(datD$discharge, by=list(datD$decMonth), FUN="sd")
colnames(sdDm) <- c("decMonth","dailySD")

#group 2017 discharge by doy
dat2017 <- filter(datD, datD$year == 2017)
dat2017ave <- aggregate(dat2017$discharge, by=list(dat2017$decMonth), FUN="mean")
colnames(dat2017ave) <- c("decMonth","dailyAve")

#bigger margins
par(mai=c(1,1,1,1))
#make plot
plot(aveDm$decMonth,aveDm$dailyAve, 
    type="l", 
    xlab="Month", 
    ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")),
    lwd=2,
    xlim = c(1,13),
    ylim=c(0,80),
    xaxs="i", yaxs ="i",#remove gaps from axes
    axes=FALSE)#no axes
polygon(c(aveDm$decMonth, rev(aveDm$decMonth)),#x coordinates
        c(aveDm$dailyAve-sdDm$dailySD,rev(aveDm$dailyAve+sdDm$dailySD)),#ycoord
        col=rgb(0.392, 0.584, 0.929,.2), #color that is semi-transparent
        border=NA#no border
        )       
lines(dat2017ave$decMonth, dat2017ave$dailyAve, col="red")
axis(1, seq(1,12, by=1), #tick intervals
        lab=seq(1,12, by=1)) #tick labels
axis(2, seq(0,100, by=20),
        seq(0,100, by=20),
        las = 2)#show ticks at 90 degree angle
legend("topright", c("2017","mean","1 standard \n deviation"), #legend items
                lwd=c(2,2,NA),#lines
                col=c("red", "black",rgb(0.392, 0.584, 0.929,.2)),#colors
                pch=c(NA,NA,15),#symbols
                 bty="n",#no legend border
       pt.cex = 1, cex=0.75)#shrink text
```

Question 6: Describe the trends streamflow in 2017 and the mean/standard deviation. After looking at this plot more closely, why do you think median and quartiles might better represent typical conditions for streamflow discharge compared to the mean and standard deviation?
```{r}
mean(dat2017ave$dailyAve)
mean(aveF$dailyAve)
sd(dat2017ave$dailyAve)
sd(aveF$dailyAve)
quantile(dat2017ave$dailyAve)
quantile(aveF$dailyAve)
```
2017 seemed to be a higher-than-average year for discharge with two large spikes in the spring and fall. Comparing the means, 2017 had only a slightly higher discharge, but the standard deviation for 2017 is double that for the average of the record period. Comparing the quantiles shows that 2017 had similar values for the lowest 75% of the data, but the top 25% of discharge values were very different from the top 25% of values in the record period averge. Means and standard deviations are highly influenced by outliers which can differ greatly from the mean with discharge data. The median and quantiles can better characterize streamflow because it shows what values are considered extreme without affecting the statistic of central tendency (the median).


Question 7: Create a dataframe that indicates what days have a full 24 hours of precipitation measurements. Make a plot of all discharge measurements and symbolize the days that have all precipitation measurements available. Be sure to include all labels.
```{r}
#create new variable for the year plus day of year
datP$yeardoy<-ifelse(leap_year(datP$year),datP$year + (datP$doy/366), datP$year + (datP$doy/365))
#create variable for rain or not
datP$tally<-1
#sum number of rain records by day
datP$rainlog<-ave(datP$tally, datP$yeardoy, FUN = sum)
#filter just days with 24 records
datP24<-filter(datP, datP$rainlog ==24)
#plot discharge
plot(datD$decYear, datD$discharge, type="l", xlab="Year", ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")), xaxs="i", yaxs ="i")
#add marks for days with 24 hours of rain data
points(datP24$yeardoy, 400*datP24$tally, col="red", pch=15)
#add a legend
legend("topright", c("Discharge","Days with 24 hours \n of precipitation data"), #legend items
                lwd=c(2,NA),#lines
                col=c("black", "red"),#colors
                pch=c(NA,15),#symbols
                 bty="n",#no legend border
       pt.cex = 1, cex=0.75)#shrink text
```

Question 8: Choose another day to make a second hydrograph during the winter. Explain how you chose a time period. How do the two hydrographs compare? Are there any limitations in interpreting the hydrograph given we only have hourly precipitation? Why do you think spikes in streamflow occur without rain?
```{r}
#find a date to make a hydrograph of with lots of variability where 24 hours of precipitation data available
#create variable for year + doy
datD$yeardoy<- ifelse(leap_year(datD$year),datD$year + (datD$doy/366), datD$year + (datD$doy/365))
#create variable calculating the range in discharge for each day
datD$spread<- ave(datD$discharge, datD$yeardoy, FUN = function(x){max(x) - min(x)})
#subset just winter days (Dec 21 to March 20)
datDwinter <- filter(datD, datD$doy < 81 | datD$doy >= 356)
#join
datDwinterjoin<-arrange(filter(left_join(datDwinter, datP24, by = c("yeardoy")), doy.y != "NA"), desc(spread))
datDwinterjoin[which.max(datDwinterjoin$spread),]
```
I chose March 8, 2008 because it had the highest range in discharge (64.6 cfs) of the winter records where 24 hours of precipitation data were available.

```{r}
#selecting just 3/8/2009
datDJ7<- filter(datD, datD$doy == 68 & datD$year == 2008)
datPJ7<- filter(datP, datP$doy == 68 & datP$year == 2008)
#setting floor and ceiling for discharge
floorJ7D <- floor(min(datDJ7$discharge))-1
ceilingJ7D <- ceiling(max(datDJ7$discharge))+1
#setting floor and ceiling for precipitation
floorJ7P<-0
ceilingJ7P<-ceiling(max(datPJ7$HPCP))+.5
#scaling precip
datPJ7$pscale <- (((ceilingJ7D-floorJ7D)/(ceilingJ7P-floorJ7P)) * datPJ7$HPCP) + floorJ7D

par(mai=c(1,1,1,1))
#make plot of discharge
plot(datDJ7$decDay,
    datDJ7$discharge, 
    type="l", 
    ylim=c(floorJ7D, ceilingJ7D), 
    lwd=2,
    xlab="Day of year", 
    ylab=expression(paste("Discharge ft"^"3 ","sec"^"-1")))
#add bars to indicate precipitation 
for(i in 1:nrow(datPJ7)){
 polygon(c(datPJ7$decDay[i]-0.017,datPJ7$decDay[i]-0.017,
            datPJ7$decDay[i]+0.017,datPJ7$decDay[i]+0.017),
        c(floorJ7D,datPJ7$pscale[i],datPJ7$pscale[i],floorJ7D),
        col=rgb(0.392, 0.584, 0.929,.2), border=NA)}
```

Compared to the first hydrograph, the discharge starts off higher at the beginning of the day and increases much more over the course of the day. The trend in the discharge rate also does not change direction in trend as much as the first hydrograph which showed multiple periods of increase and decrease with 3 small peaks. This hydrograph shows a sharp increase over just a few hours in the middle of the day, a slight dip, then another small increase, follwed by a steady decline until midnight. Using just hourly precipitation data can be limiting in cases where there are on and off showers or sudden storms with varying intensity. Since discharge is taken instantaneously and at higher frequency, it will show greater variation from observation to observation than precipitation. Spikes in streamflow could occur without rain due to snow melt. If the temperature was high enough and there was a large enough snowpack, that could cause an increase in runoff in the drainage area to feed the river. Human activities like diverting water for agricultural or industrial purposes for short periods could also cause short variations in discharge. The area is fed by a sewer, so spikes in human water use could impact discharge if the quantity of water added to the sewer was large enough.


Question 9: Make a violin plot by season for 2016 and 2017 separately. Be sure the plots are aesthetically pleasing and properly labelled. Describe differences in streamflow discharge between seasons and years.
```{r}
library(ggplot2)
#specify year as a factor
datD$yearPlot <- as.factor(datD$year)
#subset 2016 and 2017
datD1617<- filter(datD, datD$year == 2016 | datD$year == 2017)
#add season variable with ifelse
datD1617$season <- ifelse(datD1617$doy <=80 | datD1617$doy>=355, "Winter", ifelse(datD1617$doy>=81 & datD1617$doy <= 171, "Spring", ifelse(datD1617$doy >=172 & datD1617$doy <= 263, "Summer", ifelse(datD1617$doy>=264 & datD1617$doy <=354, "Fall", NA))))
#order seasons
datD1617$season<-factor(datD1617$season, levels = c("Winter", "Spring", "Summer","Fall"))
#make violin plot
datD16<-filter(datD1617, year==2016)
ggplot(data= datD16, aes(season,discharge)) + 
    geom_violin()+ggtitle("2016")+ylim(0,180)+xlab("Season")+ylab(expression(paste("Discharge ft"^"3 ","sec"^"-1")))
```
```{r}
datD17<-filter(datD1617, year==2017)
ggplot(data= datD17, aes(season,discharge)) + 
    geom_violin()+ggtitle("2017")+ylim(0,180)+xlab("Season")+ylab(expression(paste("Discharge ft"^"3 ","sec"^"-1")))
```
The discharge appears to have been more variable in 2016 than 2017 with peak discharge above 175 cfs. There were strong outliers in all seasons of 2016 likely due to some strong storms. Spring seems to have higher average discharge with the bulge in the violin plot being higher than the other seasons. This is clearer in 2017 where the data was not as widely distributed. Summer seems to have a large majority of discharge measurements in a small range (possibly indicating baseflow levels), but then large outliers likely due to storm events. Summer 2016 shows this particularly well with a very wide and short base of the violin plot but a long tail extending upwards. The biggest difference between 2016 and 2017 that I saw was in the fall where 2017 had a wider base indicating a more observations around the baseflow and 2016 had a narrower and taller base indicating that baseflow covered a broader range of discharge rates. However, Fall 2017 had


Question 10: Copy and paste the URL for your GitHub script here.
https://github.com/shannon-duffy/GEOG331/blob/master/Activity%205.Rmd

